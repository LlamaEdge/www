<!DOCTYPE html>
<html lang="en">
<head>
    <title>An all-in-one CLI app to run LLMs locally</title>
    <meta charset="UTF-8">
    <link rel="icon" href="./src/media/llamaedge-logo.svg" type="image/svg+xml">
    <link rel="stylesheet" href="./src/css/index.css"/>
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,user-scalable=yes">
    <meta name="description"
          content="The easiest & fastest way to run customized and fine-tuned LLMs locally or on the edge">
    <meta name="keywords"
          content="Run LLM locally,LLM inference,Open source LLM,ChatGPT alternative,self hosted LLM service,Priviate LLM service">
    <link href="https://fonts.googleapis.com/css?family=Kumbh+Sans:500,600,700" rel="stylesheet">
    <link href="./src/css/lite-youtube-embed.css" rel="stylesheet"/>
    <script src="./src/js/lite-youtube-embed.js"></script>
    <!-- Google tag (gtag.js) -->
    <script type="module" async src="https://www.googletagmanager.com/gtag/js?id=G-M8VQVEPV98"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-M8VQVEPV98');
    </script>
    <style>
        body {
            margin: 0;
            font-family: "Kumbh Sans", sans-serif;
        }

        .header a {
            font-size: 1.25rem;
            color: white;
        }

        a {
            text-decoration: none;
        }

        .hover-underline:hover {
            text-decoration: underline;
        }

        .codePlace {
            width: 70%;
        }

        .mobileImg {
            flex-direction: row;
        }

        .mobileSet {
            margin: 4rem;
            flex-direction: row;
        }

        .mobileSet .right {
            margin-left: 1.25rem;
            margin-top: 0;
        }

        .mobileFooter {
            flex-direction: row;
        }

        .mobileFooter .nav .child {
            margin-top: 0.5rem;
            margin-right: 4rem;
        }

        .navigation {
            display: flex;
        }

        @media (max-width: 640px) {
            .four-item {
                flex-direction: column;
            }

            .codePlace {
                width: 100%;
            }

            .mobileFooter {
                flex-direction: column;
                margin: 0 2rem;
            }

            .mobileFooter .nav {
                flex-direction: column;
            }

            .mobileFooter .nav .child {
                margin-top: 2rem;
                margin-right: 0;
            }

            .mobileImg {
                flex-direction: column;
            }

            .mobileImg img {
                max-width: 100%;
            }

            .mobileFooter .nav a {
                display: inline-block;
                margin: 0.5rem 0.5rem 0.5rem 0;
            }

            .mobileSet {
                margin: 4rem 0;
                flex-direction: column;
            }

            .mobileSet .right {
                margin-left: 0;
                margin-top: 1.25rem;
            }

            .navigation {
                display: none;
            }
        }
    </style>
</head>
<body style="background-color: black;position: relative;">
<div style="display: flex;justify-content: center;">
    <div id="text-copied"
         style="display: none;position: fixed;top:5rem;background-color: white;padding: 0.5rem 1.5rem;border: 2px solid #024BAB;border-radius: 0.5rem">
        copied!
    </div>
</div>
<div class="header" style="display: flex;align-items: center;justify-content: space-around;padding: 1.25rem 1rem;">
    <a href="https://llamaedge.webflow.io/#">
        <img src="./src/media/llamaedge.svg" loading="lazy" width="168" alt="LlamaEdge logo">
    </a>
    <div class="navigation" style="align-items: center;">
        <a href="#Feature" style="margin-right: 1.5rem">Feature</a>
        <a href="#FAQs" style="margin-right: 1.5rem">FAQ</a>
        <a href="https://huggingface.co/second-state" target="_blank"
           style="margin-right: 1.5rem">Models</a>
        <a href="https://llamaedge.com/docs/intro" target="_blank" style="margin-right: 1.5rem">Docs</a>
        <div style="width: 1px;height: 1.5rem;background-color: #e4ebf3;margin-right: 1.5rem;">
        </div>
        <a href="https://github.com/second-state/LlamaEdge" target="_blank"
           style="background: linear-gradient(360deg, #A658D0 0%, #3C2576 100%);border-radius: 0.625rem;padding: 0.65rem 1.8rem">
            View on GitHub
        </a>
        <div class="menu-button w-nav-button" style="-webkit-user-select: text;" aria-label="menu" role="button"
             tabindex="0" aria-controls="w-nav-overlay-0" aria-haspopup="menu" aria-expanded="false">
            <div class="w-icon-nav-menu"></div>
        </div>
    </div>
</div>
<div style="padding: 0 1.875rem;">
    <h1 style="margin-top: 6rem;font-size: 2.5rem;text-align: center;background: linear-gradient(180deg, #A357CD 0%, #452A7E 100%);-webkit-background-clip: text;background-clip: text;color: transparent;">
        The easiest, smallest and fastest local
        <br/>
        LLM runtime and API server.
    </h1>
    <div class="codePlace"
         style="background: linear-gradient(180deg, #A357CD 0%, #452A7E 100%);padding: 1px;border-radius: 0.8rem;margin: 0 auto;">
        <div style="border-radius: 0.8rem;background-color: black;color: white;font-size: 1.3rem;padding: 1.3rem 3rem;text-align: start;">
            <div style="display:flex;">
                <div style="width: 0.75rem;height: 0.75rem;border-radius: 0.375rem;background-color: red;margin-right: 0.8rem"></div>
                <div style="width: 0.75rem;height: 0.75rem;border-radius: 0.375rem;background-color: yellow;margin-right: 0.8rem"></div>
                <div style="width: 0.75rem;height: 0.75rem;border-radius: 0.375rem;background-color: green"></div>
            </div>
            <div style="display: flex;justify-content:space-between;align-items: center;padding: 2rem 0 1rem;">
                <div id="copyText">
                    <p style="word-break: break-all">bash <(curl -sSfL 'https://raw.githubusercontent.com/LlamaEdge/LlamaEdge/main/run-llm.sh')</p>
                </div>
                <img onclick="copyText()" style="width: 1.5rem;margin-left: 2rem;cursor: pointer;"
                     alt="copy"
                     src="./src/media/Copy.svg">
            </div>
        </div>
    </div>
    <div style="display: flex;justify-content: center;margin-top: 2.7rem;">
        <a href="https://github.com/second-state/LlamaEdge#readme" target="_blank"
           style="color: white;background: linear-gradient(90deg, #A658D0 0%, #3C2576 100%);border-radius: 0.625rem;padding: 0.65rem 1.8rem">Get
            Started</a></div>
    <div style="color: white;font-size: 1.25rem;margin-top: 2.7rem;text-align: center;">
        <span>Powered by Rust & WasmEdge (A CNCF hosted project)</span>
        <div style="position: relative;display: inline-block;">
            <a id="info-div"
               style="display: none;position: absolute;top: -2.5rem;width: max-content;font-size: 0.6rem;cursor: pointer;text-decoration-line:underline;"
               href="https://www.secondstate.io/articles/fast-llm-inference/" target="_blank">
                <div class="hover-underline"
                     style="padding: 0.5rem 1rem;border: 1px solid #024BAB;border-radius: 0.7rem;background-color: white;color: black;">
                    Learn why choose Rust + Wasm tech stack
                </div>
            </a>
            <img alt="info" id="info-icon" style="width: 1.2rem;margin-left: 0.2rem;cursor: pointer;"
                 src="./src/media/Info.svg">
        </div>
    </div>
    <div id="Feature" class="mobileSet" style="display: flex;justify-content:space-around;color: white;">
        <div style="flex: 1;padding: 2rem 1.7rem;background: linear-gradient(90deg, #A658D0 0%, #3C2576 100%);display: flex;justify-content: center;flex-direction: column;border-radius: 1.25rem;">
            <div style="font-size: 2rem;font-weight: bold;">Lightweight</div>
            <div style="font-size: 1.25rem;margin-top: 2rem;">
                Runtime + API server is less than <span style="font-size: 2rem;font-weight: bold;">30MB</span>. No
                external dependency. Zero Python packages.
            </div>
        </div>
        <div class="right"
             style="flex: 1;background: linear-gradient(90deg, #A658D0 0%, #3C2576 100%);border-radius: 1.25rem;padding: 3px;display: flex;justify-content: center;flex-direction: column;">
            <div class="mobileImg"
                 style="display: flex;height: 100%;background-color: black;padding: 2rem 1.7rem;border-radius: 1.25rem;justify-content: space-between;align-items: center;">
                <div>
                    <div style="font-size: 2rem;font-weight: bold;">Very fast</div>
                    <div style="font-size: 1.25rem;margin-top: 2rem;">Automagically use the device's local hardware and
                        software acceleration.
                    </div>
                </div>
                <img alt="picture" style="max-height: 12rem;" src="./src/media/all-logo.webp">
            </div>
        </div>
    </div>
    <h1 style="margin-top: 8rem;font-size: 2.5rem;text-align: center;background: linear-gradient(180deg, #A357CD 0%, #452A7E 100%);-webkit-background-clip: text;background-clip: text;color: transparent;">
        Cross-platform LLM agents and web services in Rust or JavaScript</h1>
    <div class="mobileSet" style="display: flex;justify-content:space-around;color: white;">
        <div style="flex: 1;background: linear-gradient(90deg, #A658D0 0%, #3C2576 100%);border-radius: 1.25rem;padding: 3px;display: flex;justify-content: space-between;flex-direction: column;">
            <div style="height: 100%;background-color: black;padding: 2rem 1.7rem;border-radius: 1.25rem;">
                <div style="font-size: 2rem;">Write once run anywhere, for GPUs</div>
                <div style="font-size: 1.5rem;margin-top: 1.7rem;">Create an LLM web service on a MacBook, deploy it on
                    a NVIDIA device.
                </div>
                <lite-youtube
                        style="border: 1px solid #787878;width: 100%;max-width: 95vw;border-radius: 2rem;margin-top: 2.3rem;"
                        videoid="cPzQ9pBmRJc"></lite-youtube>
            </div>
        </div>
        <div class="right"
             style="flex: 1;padding: 2rem 1.7rem;background: linear-gradient(90deg, #A658D0 0%, #3C2576 100%);display: flex;justify-content: space-between;flex-direction: column;border-radius: 1.25rem;">
            <div style="font-size: 2rem;">Native to the heterogeneous edge</div>
            <div style="font-size: 1.5rem;margin-top: 1.7rem;">Orchestrate and move an LLM app across CPUs, GPUs and
                NPUs.
            </div>
            <lite-youtube
                    style="border: 1px solid #787878;width: 100%;max-width: 95vw;border-radius: 2rem;margin-top: 2.3rem;"
                    videoid="7NJnFVei8d0"></lite-youtube>
        </div>
    </div>
</div>
<div class="four-item"
     style="text-align: center;display: flex;justify-content: space-around;background-color: #f5f7fa;padding:3.75rem 0;">
    <div style="flex: 1;display: flex;justify-content: space-around;">
        <div style="flex: 1">
            <div style="font-weight: 700;font-size: 2.5rem;margin-bottom:0.5rem;background: linear-gradient(180deg, #A357CD 0%, #452A7E 100%);-webkit-background-clip: text;background-clip: text;color: transparent;">
                2~4<span
                    style="font-size: 1.5rem;">MB</span></div>
            <div>Inference app</div>
        </div>
        <div style="flex: 1">
            <div style="font-weight: 700;font-size: 2.5rem;margin-bottom:0.5rem;background: linear-gradient(180deg, #A357CD 0%, #452A7E 100%);-webkit-background-clip: text;background-clip: text;color: transparent;">
                30<span
                    style="font-size: 1.5rem;">MB</span></div>
            <div>Total dependency</div>
        </div>
    </div>
    <div style="flex: 1;display: flex;justify-content: space-around;">
        <div style="flex: 1">
            <div style="font-weight: 700;font-size: 2.5rem;margin-bottom:0.5rem;background: linear-gradient(180deg, #A357CD 0%, #452A7E 100%);-webkit-background-clip: text;background-clip: text;color: transparent;">
                1000+
            </div>
            <div>Llama2 series of models</div>
        </div>
        <div style="flex: 1">
            <div style="font-weight: 700;font-size: 2.5rem;margin-bottom:0.5rem;background: linear-gradient(180deg, #A357CD 0%, #452A7E 100%);-webkit-background-clip: text;background-clip: text;color: transparent;">
                100<span
                    style="font-size: 1.5rem;">%</span></div>
            <div>Native spped</div>
        </div>
    </div>
</div>
<div style="padding:0 1.875rem;">
    <div style="color: white;padding:5rem 0;display: flex;justify-content: center;font-size: 1.25rem;">
        <div id="FAQs" class="codePlace">
            <h2 style="font-weight: 700;font-size: 2rem;text-align: center;">FAQs</h2>
            <p style="text-align: center;"> Learn more about LlamaEdge</p>
            <div style="padding-bottom:1.25rem;">
                <span style="font-weight: bold;margin-bottom: 20px;">Q: Why can't I just use the OpenAI API?</span>
                <p style="margin-bottom: 20px">A: Hosted LLM APIs are easy to use. But they are also expensive and difficult to customize for your own apps. The hosted LLMs are heavily censored (aligned, or “dumbed down”) generalists. It currently costs you millions of dollars and months of time to ask OpenAI to fine-tune ChatGPT for your own knowledge domain.</p> 
                <p style="margin-bottom: 20px">Furthermore, hosted LLMs are not private. You are at risk of leaking your data and privacy to the LLM hosting companies. In fact, OpenAI requires you to pay more for a “promise” not to use your interaction data in future training. </p>
            </div>
            <div style="padding-bottom:1.25rem;">
                <span style="font-weight: bold;margin-bottom: 20px;">Q: Why can't I just start an OpenAI-compatible API server over an open-source model, and then use frameworks like LangChain or LlamaIndex in front of the API to build my app?</span>
                <p style="margin-bottom: 20px">A: You sure can! In fact, you can start an <a href="https://github.com/LlamaEdge/LlamaEdge/tree/main/api-server">OpenAI-compatible API server using LlamaEdge</a>. LlamaEdge automagically utilizes the hardware accelerator and software runtime library in your device.</p> 
                <p style="margin-bottom: 20px">However, often times, we need an compact and integrated solution, instead of a jumbo mixture of LLM runtime, API server, Python middleware, UI, and other glue code to tie them together.</p>
                <p style="margin-bottom: 20px">LlamaEdge provides a set of modular components for you to assemble your own LLM agents and applications like Lego blocks. You can do this entirely in Rust or JavaScript, and compile down to a self-contained application binary that runs without modification across many devices.</p>
            </div>
            <div style="padding-bottom:1.25rem;">
                <span style="font-weight: bold;margin-bottom: 20px;">Q: Why can't I use Python to run the LLM inference?</span>
                <p style="margin-bottom: 20px">A: You can certainly use Python to run LLMs and even start an API server using Python. But keep mind that PyTorch has over 5GB of complex dependencies. These dependencies often conflict with Python toolchains such as LangChain. It is often a nightmare to set up Python dependencies across dev and deployment machines, especially with GPUs and containers.</p> 
                <p style="margin-bottom: 20px">In contrast, the entire LlamaEdge runtime is less than 30MB. It is has no external dependencies. Just install LlamaEdge and copy over your compiled application file! </p>
            </div>
            <div style="padding-bottom:1.25rem;">
                <span style="font-weight: bold;margin-bottom: 20px;">Q: Why can't I just use native (C/C++ compiled) inference engines?</span>
                <p style="margin-bottom: 20px">A: The biggest issue with native compiled apps is that they are not portable. You must rebuild and retest for each computer you deploy the application. It is a very tedious and error prone progress. LlamaEdge programs are written in Rust (soon JS) and compiled to Wasm. The Wasm app runs as fast as native apps, and is entirely portable.</p> 
            </div>
        </div>
    </div>
</div>
<div style="background-color: #f5f7fa;padding: 3rem 0 1rem;">
    <div class="mobileFooter" style="display: flex;justify-content: space-around;">
        <a href="https://llamaedge.webflow.io/#">
            <img src="./src/media/llamaedge-with-black.svg" loading="lazy" width="256" alt="llamaedge_logo">
        </a>
        <div class="nav" style="display: flex;">
            <div class="child">
                <div style="font-weight: 700;font-size: 1.25rem;margin-bottom: 0.5rem;">LlamaEdge</div>
                <a href="">How it works</a>
                <br/>
                <a href="https://www.secondstate.io/articles/run-llm-sh/">Docs</a>
            </div>
            <div class="child">
                <div style="font-weight: 700;font-size: 1.25rem;margin-bottom: 0.5rem;">Resources</div>
                <a href="https://www.secondstate.io/categories/llm/">LLM  Tutorials</a>
                <br/>
                <a href="https://www.secondstate.io/articles/selfhost-huggingface-llms/">Run your own model with LlamaEdge</a>
                <br/>
                <a href="https://github.com/second-state/LlamaEdge">Source code</a>
            </div>
            <div class="child">
                <div style="font-weight: 700;font-size: 1.25rem;margin-bottom: 0.5rem;">Contact US</div>
                <div class="footer-social-block">
                    <a href="https://twitter.com/realwasmedge">
                        <img src="./src/media/twitter.svg" loading="lazy" alt="twitter_logo">
                    </a>
                    <a
                            href="https://discord.gg/qCwvnwvtYU">
                        <img src="./src/media/discord.svg" loading="lazy" alt="discord_logo">
                    </a>
                    <a href="https://github.com/second-state/LlamaEdge">
                        <img src="./src/media/GitHub.svg" loading="lazy" alt="github_logo">
                    </a>
                </div>
            </div>
        </div>
    </div>
    <div style="width: 100%;height: 1px;background-color: #e4ebf3;margin-top: 4rem;margin-bottom: 1rem;"></div>
    <div style="color:#333;text-align: center;">Copyright © 2024 Second State</div>
</div>
<script>

    const infoIcon = document.getElementById('info-icon');
    const infoDiv = document.getElementById('info-div');
    const textCopied = document.getElementById('text-copied');
    let isHoveringInfoDiv = false;

    infoIcon.addEventListener('mouseenter', () => {
        infoDiv.style.display = 'block';
    });

    infoDiv.addEventListener('mouseenter', () => {
        isHoveringInfoDiv = true;
    });

    infoIcon.addEventListener('mouseleave', () => {
        setTimeout(() => {
            if (!isHoveringInfoDiv) {
                infoDiv.style.display = 'none';
            }
        }, 100)
    });

    infoDiv.addEventListener('mouseleave', () => {
        isHoveringInfoDiv = false;
        infoDiv.style.display = 'none';
    });

    function copyText() {
        textCopied.style.display = 'block';
        const text = document.getElementById("copyText").innerText;
        copyTextToClipboard(text);
        setTimeout(() => {
            textCopied.style.display = 'none';
        }, 1000)
    }

    function copyTextToClipboard(text) {
        const textArea = document.createElement("textarea");
        textArea.value = text;
        document.body.appendChild(textArea);
        textArea.select();
        navigator.clipboard.writeText(text);
        document.body.removeChild(textArea);
    }

    //
    // document.addEventListener('DOMContentLoaded', function () {
    //     console.log("DOMContentLoaded")
    //     let tag = document.createElement('script');
    //
    //     tag.src = "https://www.youtube.com/iframe_api";
    //     let firstScriptTag = document.getElementsByTagName('script')[0];
    //     firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);
    // })
    //
    // function onYouTubeIframeAPIReady() {
    //     console.log("onYouTubeIframeAPIReady")
    //     new YT.Player('left-player', {
    //         width: '100%',
    //         videoId: 'RFBneB9Ri4U',
    //     });
    //
    //     new YT.Player('right-player', {
    //         width: '100%',
    //         videoId: 'B37Ru2UK7Yg',
    //     });
    // }
</script>
</body>
</html>
