"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[595],{4997:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>a,toc:()=>l});var s=n(4848),d=n(8453);const o={sidebar_position:1},i="Working with embedding models",a={id:"ai-models/embeddings/index",title:"Working with embedding models",description:"Embedding models compute vectors from text inputs. The vectors can then be used as search index",source:"@site/docs/ai-models/embeddings/index.md",sourceDirName:"ai-models/embeddings",slug:"/ai-models/embeddings/",permalink:"/docs/ai-models/embeddings/",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ai-models/embeddings/index.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Embeddings",permalink:"/docs/category/embeddings"},next:{title:"Speech to Text",permalink:"/docs/category/speech-to-text"}},r={},l=[{value:"Step 1: Install WasmEdge",id:"step-1-install-wasmedge",level:3},{value:"Step 2: Download the embedding model",id:"step-2-download-the-embedding-model",level:3},{value:"Step 3: Download a portable API server app",id:"step-3-download-a-portable-api-server-app",level:3},{value:"Step 4: Start the API server",id:"step-4-start-the-api-server",level:3},{value:"Step 5: Use the /embeddings API",id:"step-5-use-the-embeddings-api",level:3}];function c(e){const t={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h3:"h3",p:"p",pre:"pre",strong:"strong",...(0,d.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"working-with-embedding-models",children:"Working with embedding models"}),"\n",(0,s.jsx)(t.p,{children:"Embedding models compute vectors from text inputs. The vectors can then be used as search index\nfor semantic search in a vector database."}),"\n",(0,s.jsx)(t.h3,{id:"step-1-install-wasmedge",children:"Step 1: Install WasmEdge"}),"\n",(0,s.jsx)(t.p,{children:"First off, you'll need WasmEdge, a high-performance, lightweight, and extensible WebAssembly (Wasm) runtime optimized for server-side and edge computing. To install WasmEdge along with the necessary plugin for AI inference, open your terminal and execute the following command:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install_v2.sh | bash -s\n"})}),"\n",(0,s.jsx)(t.p,{children:"This command fetches and runs the WasmEdge installation script, which automatically installs WasmEdge and the WASI-NN plugin, essential for running LLM models like Llama 3.1."}),"\n",(0,s.jsx)(t.h3,{id:"step-2-download-the-embedding-model",children:"Step 2: Download the embedding model"}),"\n",(0,s.jsxs)(t.p,{children:["Next, you'll need to obtain a model file. For this tutorial, we're focusing on the ",(0,s.jsx)(t.strong,{children:"GTW Qwen2 1.5B"})," model, which is a top rated text embedding model from Qwen. It generates vectors of 1536 dimensions. The steps are generally applicable to other models too. Use the following command to download the model file."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"curl -LO https://huggingface.co/second-state/gte-Qwen2-1.5B-instruct-GGUF/resolve/main/gte-Qwen2-1.5B-instruct-Q5_K_M.gguf\n"})}),"\n",(0,s.jsx)(t.h3,{id:"step-3-download-a-portable-api-server-app",children:"Step 3: Download a portable API server app"}),"\n",(0,s.jsxs)(t.p,{children:["Next, you need an application that can build an OpenAI compatible API server for the model.\nThe ",(0,s.jsx)(t.a,{href:"https://github.com/LlamaEdge/LlamaEdge/tree/main/llama-api-server",children:"LlamaEdge api server app"})," is a lightweight and cross-platform Wasm app that works on any device\nyou might have. Just download the compiled binary app."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"curl -LO https://github.com/second-state/LlamaEdge/releases/latest/download/llama-api-server.wasm\n"})}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"The LlamaEdge apps are written in Rust and compiled to portable Wasm. That means they can run across devices and OSes without any change to the binary apps. You can simply download and run the compiled wasm apps regardless of your platform."}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"step-4-start-the-api-server",children:"Step 4: Start the API server"}),"\n",(0,s.jsxs)(t.p,{children:["Start the API server with the following command. Notice that the context size of this particular embedding model is\n32k and the prompt template is ",(0,s.jsx)(t.code,{children:"embedding"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"wasmedge --dir .:. --nn-preload default:GGML:AUTO:gte-Qwen2-1.5B-instruct-Q5_K_M.gguf llama-api-server.wasm --model-name gte-qwen2-1.5b --ctx-size 32768 --batch-size 8192 --ubatch-size 8192 --prompt-template embedding\n"})}),"\n",(0,s.jsx)(t.h3,{id:"step-5-use-the-embeddings-api",children:"Step 5: Use the /embeddings API"}),"\n",(0,s.jsxs)(t.p,{children:["You can now send embedding requests to it using the OpenAI-compatible ",(0,s.jsx)(t.code,{children:"/embeddings"})," API endpoint."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:'curl http://localhost:8080/v1/embeddings \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "input": "The food was delicious and the waiter..."\n  }\'\n'})}),"\n",(0,s.jsx)(t.p,{children:"The response is."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:'{"object":"list","data":[{"index":0,"object":"embedding","embedding":[0.02968290634,0.04592291266,0.05229084566,-0.001912750886,-0.01647545397,0.01744602434,0.008423444815,0.01363539882,-0.005849621724,-0.004947130103,-0.02326701023,0.1068811566,0.01074867789, ... 0.005662892945,-0.01796873659,0.02428019233,-0.0333112292]}],"model":"gte-qwen2-1.5b","usage":{"prompt_tokens":9,"completion_tokens":0,"total_tokens":9}}\n'})})]})}function p(e={}){const{wrapper:t}={...(0,d.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>a});var s=n(6540);const d={},o=s.createContext(d);function i(e){const t=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(d):e.components||d:i(e.components),s.createElement(o.Provider,{value:t},e.children)}}}]);