"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5322],{6931:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>i,contentTitle:()=>n,default:()=>c,frontMatter:()=>t,metadata:()=>r,toc:()=>d});var s=o(4848),l=o(8453);const t={sidebar_position:4},n="LlamaEdge vs Ollama",r={id:"llamaedge_vs_ollama",title:"LlamaEdge vs Ollama",description:'There are several popular tools to run "local LLMs". Ollama is one of the earlist and most popular. Why do people',source:"@site/docs/llamaedge_vs_ollama.md",sourceDirName:".",slug:"/llamaedge_vs_ollama",permalink:"/docs/llamaedge_vs_ollama",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/llamaedge_vs_ollama.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"LlamaEdge vs llama.cpp",permalink:"/docs/llamaedge_vs_llamacpp"},next:{title:"Serve AI models",permalink:"/docs/category/serve-ai-models"}},i={},d=[];function m(e){const a={h1:"h1",li:"li",p:"p",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.h1,{id:"llamaedge-vs-ollama",children:"LlamaEdge vs Ollama"}),"\n",(0,s.jsx)(a.p,{children:'There are several popular tools to run "local LLMs". Ollama is one of the earlist and most popular. Why do people\nchoose LlamaEdge over them?'}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"LlamaEdge is very small. The entire runtime and application is only 30MB. That is about 1/3 of the nearest competitor."}),"\n",(0,s.jsx)(a.li,{children:"LlamaEdge does not need root or sudo permissions. It does not install or run any daemon on your system. Hence LlamaEdge can be easily embedded into your own app."}),"\n",(0,s.jsx)(a.li,{children:"LlamaEdge apps are cross-platform. A single binary file can run on all supported OSes, CPUs, and GPUs. That also makes it simple to embed LlamaEdge in your apps."}),"\n",(0,s.jsx)(a.li,{children:"Through Docker integration, an LlamaEdge container combines model files, configurations, and runtime into a single package ensuring compatibility and portability over time. All from the Docker Hub you already use."}),"\n",(0,s.jsx)(a.li,{children:"LlamaEdge supports alternative runtimes beyond llama.cpp to achieve the most optimal performance for your model and hardware."}),"\n",(0,s.jsx)(a.li,{children:"LlamaEdge already supports multimodal vision models. It will soon support speech-to-text and text-to-image models through as OpenAI-compatible APIs."}),"\n",(0,s.jsxs)(a.li,{children:["LlamaEdge is more secure. ",(0,s.jsx)(a.strong,{children:"LlamaEdge server is a sandboxed Wasm"})," and does not require root privileges. So it is much harder to exploit."]}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"Finally, LlamaEdge is a developer platform. It provides Rust APIs and components for you to build your own applications.\nIt enables developers to create a single compact and cross-platform binary app that can be easily deployed and orchestrated across clouds."})]})}function c(e={}){const{wrapper:a}={...(0,l.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(m,{...e})}):m(e)}},8453:(e,a,o)=>{o.d(a,{R:()=>n,x:()=>r});var s=o(6540);const l={},t=s.createContext(l);function n(e){const a=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:n(e.components),s.createElement(t.Provider,{value:a},e.children)}}}]);