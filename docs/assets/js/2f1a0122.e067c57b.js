"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[348],{2764:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var o=s(4848),n=s(8453);const i={sidebar_position:5},l="FlowiseAI tool call",r={id:"user-guide/openai-api/flowiseai-tool-call",title:"FlowiseAI tool call",description:"FlowiseAI is a low-code tool for developers to build customized LLM orchestration flows & AI agents.",source:"@site/docs/user-guide/openai-api/flowiseai-tool-call.md",sourceDirName:"user-guide/openai-api",slug:"/user-guide/openai-api/flowiseai-tool-call",permalink:"/docs/user-guide/openai-api/flowiseai-tool-call",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/user-guide/openai-api/flowiseai-tool-call.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Obsidian",permalink:"/docs/user-guide/openai-api/obsidian"},next:{title:"Translation Agent",permalink:"/docs/user-guide/openai-api/translation-agent"}},a={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Start a FlowiseAI server",id:"start-a-flowiseai-server",level:2},{value:"Build a chatbot for realtime IP lookup",id:"build-a-chatbot-for-realtime-ip-lookup",level:2},{value:"Give it a try",id:"give-it-a-try",level:2}];function d(e){const t={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"flowiseai-tool-call",children:"FlowiseAI tool call"}),"\n",(0,o.jsxs)(t.p,{children:["FlowiseAI is a low-code tool for developers to build customized LLM orchestration flows & AI agents.\nYou can configure the FlowiseAI tool to use a local LlamaEdge LLM that supports ",(0,o.jsx)(t.a,{href:"https://github.com/LlamaEdge/LlamaEdge/blob/main/api-server/ToolUse.md",children:"tool calling"}),"."]}),"\n",(0,o.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(t.p,{children:["Follow ",(0,o.jsx)(t.a,{href:"/docs/intro",children:"this guide"})," to run an open-source LLM locally.\nIn this example, we need an open source LLM that is capable of generating tool call (JSON) responses.\nThe Mistral v0.3 7B model is a good choice here."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"curl -LO https://huggingface.co/second-state/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3-Q5_K_M.gguf\n"})}),"\n",(0,o.jsxs)(t.p,{children:["Then start the LlamaEdge API server with the Mistral model and name it ",(0,o.jsx)(t.code,{children:"Mistral-7B-Instruct-v0.3.Q5_K_M"}),"."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"wasmedge --dir .:. \\\n    --nn-preload default:GGML:AUTO:Mistral-7B-Instruct-v0.3.Q5_K_M.gguf \\\n    --nn-preload embedding:GGML:AUTO:nomic-embed-text-v1.5.f16.gguf \\\n    llama-api-server.wasm \\\n    --model-alias default,embedding \\\n    --model-name Mistral-7B-Instruct-v0.3.Q5_K_M,nomic-embed-text-v1.5.f16 \\\n    --prompt-template mistral-tool,embedding \\\n    --batch-size 128,8192 \\\n    --ctx-size 32768,8192\n"})}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsxs)(t.p,{children:["You can ",(0,o.jsx)(t.a,{href:"https://github.com/GaiaNet-AI/node-configs/tree/main/mistral-0.3-7b-instruct-tool-call",children:"start a Gaia node"})," for the ",(0,o.jsx)(t.code,{children:"Mistral-7B-Instruct-v0.3.Q5_K_M"})," model with tool call support. You can then use the node's API URL endpoint and model name in your tool call apps."]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"start-a-flowiseai-server",children:"Start a FlowiseAI server"}),"\n",(0,o.jsxs)(t.p,{children:["Follow ",(0,o.jsx)(t.a,{href:"https://docs.flowiseai.com/getting-started",children:"the FlowiseAI guide"})," to install Flowise locally"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"npm install -g flowise\nnpx flowise start\n"})}),"\n",(0,o.jsxs)(t.p,{children:["After running successfully, you can open ",(0,o.jsx)(t.code,{children:"http://localhost:3000"})," to check out the Flowise AI tool."]}),"\n",(0,o.jsx)(t.h2,{id:"build-a-chatbot-for-realtime-ip-lookup",children:"Build a chatbot for realtime IP lookup"}),"\n",(0,o.jsxs)(t.p,{children:["Step 1: Create a new ",(0,o.jsx)(t.strong,{children:"Chatflow"})," from the UI."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:s(8547).A+"",width:"832",height:"402"})}),"\n",(0,o.jsxs)(t.p,{children:["Step 2: On the ",(0,o.jsx)(t.strong,{children:"Chatflow"})," canvas, add a node called ",(0,o.jsx)(t.strong,{children:"ChatLocalAI"}),"."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:s(2792).A+"",width:"684",height:"854"})}),"\n",(0,o.jsxs)(t.p,{children:["Step 3: Configure the ",(0,o.jsx)(t.strong,{children:"ChatLocalAI"})," widget to use the local LlamaEdge."]}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:["Base path: ",(0,o.jsx)(t.code,{children:"http://localhost:8080/v1"})]}),"\n",(0,o.jsxs)(t.li,{children:["Model name: e.g., ",(0,o.jsx)(t.code,{children:"Mistral-7B-Instruct-v0.3.Q5_K_M"})]}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["Step 4: Add a node called ",(0,o.jsx)(t.strong,{children:"Custom Tool"})]}),"\n",(0,o.jsxs)(t.p,{children:["Create a function named ",(0,o.jsx)(t.code,{children:"get_ip_address_geo_location"}),".\nThe function requires a ",(0,o.jsx)(t.code,{children:"string"})," parameter called ",(0,o.jsx)(t.code,{children:"ip"}),"."]}),"\n",(0,o.jsxs)(t.p,{children:["The ",(0,o.jsx)(t.strong,{children:"Tool description"}),' field is the "prompt" that tells the LLM when to use this function. In this example,\nif the LLM detects that the user is asking about the city or country of an IP address, it will\nreturn a tool call response asking FlowiseAI to perform this function call first.']}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:s(3921).A+"",width:"832",height:"706"})}),"\n",(0,o.jsxs)(t.p,{children:["Now you can add JavaScript code for this function. It looks up the location of the input ",(0,o.jsx)(t.code,{children:"ip"})," parameter."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:'const fetch = require("node-fetch")\nconst url = "http://ipwho.is/"+$ip\n\ntry {\n  const response = await fetch(url)\n  const result = await response.text()\n  console.log(result)\n  return result\n} catch(error) {\n  console.error(error)\n}\n'})}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:s(6206).A+"",width:"832",height:"702"})}),"\n",(0,o.jsxs)(t.p,{children:["Step 5: Add a node called ",(0,o.jsx)(t.strong,{children:"Buffer Memory"})," to the canvas."]}),"\n",(0,o.jsxs)(t.p,{children:["Step 6: Add a node called ",(0,o.jsx)(t.strong,{children:"Tool Agent"}),"."]}),"\n",(0,o.jsx)(t.p,{children:"Step 7: Connect the nodes."}),"\n",(0,o.jsxs)(t.p,{children:["Connect the ",(0,o.jsx)(t.strong,{children:"Custom Tool"})," and ",(0,o.jsx)(t.strong,{children:"Buffer Memory"})," nodes to the appropriate connectors on the\n",(0,o.jsx)(t.strong,{children:"Tool Agent"})," node. Connect the ",(0,o.jsx)(t.strong,{children:"ChatLocalAI"})," node to the ",(0,o.jsx)(t.strong,{children:"Custom Tool"}),"."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:s(1783).A+"",width:"1274",height:"684"})}),"\n",(0,o.jsxs)(t.p,{children:["Step 8: Save the ",(0,o.jsx)(t.strong,{children:"Chatflow"}),"."]}),"\n",(0,o.jsx)(t.h2,{id:"give-it-a-try",children:"Give it a try"}),"\n",(0,o.jsxs)(t.p,{children:["From the FlowiseAI UI, you can open a chat window to chat with the ",(0,o.jsx)(t.strong,{children:"ChatLocalAI"})," you just created. Let's\nask a question:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"What's the location of this address 35.222.115.181\n"})}),"\n",(0,o.jsxs)(t.p,{children:["The LLM understands that the request is to find a location for an IP address, and sees that we have a function\ncalled ",(0,o.jsx)(t.code,{children:"get_ip_address_geo_location"})," in tools, which has a description that matches this task.\nSo, it responses with a JSON message to call this function with\nthe IP address it extracts from the user query."]}),"\n",(0,o.jsxs)(t.p,{children:["This tool calling JSON message is NOT displayed to the user in the chatbot. Instead, the FlowiseAI\n",(0,o.jsx)(t.strong,{children:"Custom Tool"})," node captures it and executes the JavaScript code associated with this tool call. The result of\nthe tool call is then sent back to the LLM together with the original query,\nwhich is why we need the ",(0,o.jsx)(t.strong,{children:"Buffer Memory"})," node BTW,\nand the LLM formulates a human readable response to the original question."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:s(3676).A+"",width:"726",height:"1242"})})]})}function h(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8547:(e,t,s)=>{s.d(t,{A:()=>o});const o=s.p+"assets/images/flowise-tool-01-54bc5131cf142cebbfc44675f276c962.png"},2792:(e,t,s)=>{s.d(t,{A:()=>o});const o=s.p+"assets/images/flowise-tool-02-82e1dcf92b2aceeccff81ac1e7e891de.png"},3921:(e,t,s)=>{s.d(t,{A:()=>o});const o=s.p+"assets/images/flowise-tool-03-93283784efe5a1f1343443da51c35c88.png"},6206:(e,t,s)=>{s.d(t,{A:()=>o});const o=s.p+"assets/images/flowise-tool-04-9217ad7610930f56bc859d250c1538ec.png"},1783:(e,t,s)=>{s.d(t,{A:()=>o});const o=s.p+"assets/images/flowise-tool-05-8cf21165d8466b203f3f521ba9e55b61.png"},3676:(e,t,s)=>{s.d(t,{A:()=>o});const o=s.p+"assets/images/flowise-tool-06-3691b227be09ee5bd6e7c6badf78c2ff.png"},8453:(e,t,s)=>{s.d(t,{R:()=>l,x:()=>r});var o=s(6540);const n={},i=o.createContext(n);function l(e){const t=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:l(e.components),o.createElement(i.Provider,{value:t},e.children)}}}]);