"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1671],{2692:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>d});var a=n(4848),s=n(8453);const o={sidebar_position:2},r="LlamaEdge vs Python",i={id:"llamaedge_vs_python",title:"LlamaEdge vs Python",description:"Most AI models are trained and even finetuned in Python / PyTorch, but you should not deploy and run them in Python.",source:"@site/docs/llamaedge_vs_python.md",sourceDirName:".",slug:"/llamaedge_vs_python",permalink:"/docs/llamaedge_vs_python",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/llamaedge_vs_python.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"LlamaEdge",permalink:"/docs/intro"},next:{title:"LlamaEdge vs llama.cpp",permalink:"/docs/llamaedge_vs_llamacpp"}},l={},d=[];function c(e){const t={a:"a",h1:"h1",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h1,{id:"llamaedge-vs-python",children:"LlamaEdge vs Python"}),"\n",(0,a.jsxs)(t.p,{children:["Most AI models are trained and even finetuned in Python / PyTorch, but you should not deploy and run them in Python.\nIn fact, running production level AI inference in Python is extremely inefficient -- a natively compiled language\ncan be ",(0,a.jsx)(t.a,{href:"https://www.modular.com/blog/how-mojo-gets-a-35-000x-speedup-over-python-part-1",children:"35,000x faster than Python"}),".\nDevelopers choose LlamaEdge over Python because:"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["LlamaEdge is only 1/100 the size of a Python runtime. Do you know that the smallest PyTorch Docker image is ",(0,a.jsx)(t.a,{href:"https://hub.docker.com/r/pytorch/pytorch/tags",children:"almost 4GB"}),"?"]}),"\n",(0,a.jsxs)(t.li,{children:["LlamaEdge is a single install package with no complex dependencies. It is very easy to install and get started. It does not take the ",(0,a.jsx)(t.a,{href:"https://twitter.com/santiviquez/status/1676677829751177219",children:"best minds of our generation"})," to install it."]}),"\n",(0,a.jsxs)(t.li,{children:["Developers can create LlamaEdge apps in Rust, which is much faster than Python in pre and post processing data that goes into the model. A good example is the ",(0,a.jsx)(t.a,{href:"https://github.com/LlamaEdge/LlamaEdge/tree/main/api-server",children:"LlamaEdge chatbot and API server"})," -- it is orders of magnitudes faster than Python-based web app servers."]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["Learn more: ",(0,a.jsx)(t.a,{href:"https://blog.stackademic.com/why-did-elon-musk-say-that-rust-is-the-language-of-agi-eb36303ce341",children:"Why did Elon Musk say that Rust is the Language of AGI?"})]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>i});var a=n(6540);const s={},o=a.createContext(s);function r(e){const t=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),a.createElement(o.Provider,{value:t},e.children)}}}]);