"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[322],{6931:(e,a,s)=>{s.r(a),s.d(a,{assets:()=>i,contentTitle:()=>t,default:()=>m,frontMatter:()=>l,metadata:()=>r,toc:()=>d});var o=s(4848),n=s(8453);const l={sidebar_position:4},t="LlamaEdge vs Ollama",r={id:"llamaedge_vs_ollama",title:"LlamaEdge vs Ollama",description:'There are several popular tools to run "local LLMs". Ollama is one of the earlist and most popular. Why do people',source:"@site/docs/llamaedge_vs_ollama.md",sourceDirName:".",slug:"/llamaedge_vs_ollama",permalink:"/docs/llamaedge_vs_ollama",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/llamaedge_vs_ollama.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"LlamaEdge vs llama.cpp",permalink:"/docs/llamaedge_vs_llamacpp"},next:{title:"User Guide",permalink:"/docs/category/user-guide"}},i={},d=[];function c(e){const a={a:"a",h1:"h1",li:"li",p:"p",ul:"ul",...(0,n.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(a.h1,{id:"llamaedge-vs-ollama",children:"LlamaEdge vs Ollama"}),"\n",(0,o.jsx)(a.p,{children:'There are several popular tools to run "local LLMs". Ollama is one of the earlist and most popular. Why do people\nchoose LlamaEdge over them?'}),"\n",(0,o.jsxs)(a.ul,{children:["\n",(0,o.jsx)(a.li,{children:"LlamaEdge is very small. The entire runtime and application is only 30MB. That is about 1/3 of the nearest competitor."}),"\n",(0,o.jsx)(a.li,{children:"LlamaEdge does not need root or sudo permissions It does not install or run any daemon on your system. Hence LlamaEdge can be easily embedded into your own app."}),"\n",(0,o.jsx)(a.li,{children:"LlamaEdge works with model files you download from Huggingface. There is no need for a special download hub."}),"\n",(0,o.jsx)(a.li,{children:"LlamaEdge provides a fully featured API server that supports both chat and embedding models in OpenAI-compatible API formats."}),"\n",(0,o.jsx)(a.li,{children:"LlamaEdge already supports for multimodal vision models. It will soon support text-to-image, and voice models soon through a unified OpenAI-compatible API."}),"\n"]}),"\n",(0,o.jsx)(a.p,{children:"Finally, LlamaEdge is a developer platform. It provides Rust APIs and components for you to build your own applications.\nIt enables developers to create a single compact and cross-platform binary app that can be easily deployed and orchestrated across clouds."}),"\n",(0,o.jsxs)(a.ul,{children:["\n",(0,o.jsxs)(a.li,{children:["The ",(0,o.jsx)(a.a,{href:"user-guide/server-side-rag/quick-start",children:"server-side RAG"})," API server is built on LlamaEdge components."]}),"\n",(0,o.jsxs)(a.li,{children:["The ",(0,o.jsx)(a.a,{href:"https://github.com/project-robius/moxin",children:"moxin"})," LLM client app uses LlamaEdge as the embedded inference engine."]}),"\n",(0,o.jsxs)(a.li,{children:["The ",(0,o.jsx)(a.a,{href:"https://github.com/GaiaNet-AI/gaianet-node",children:"GaiaNet"})," project embeds LlamaEdge to run a large number of decentralized LLM agents across the web."]}),"\n",(0,o.jsxs)(a.li,{children:["The ",(0,o.jsx)(a.a,{href:"https://www.jointerminus.com/",children:"Terminus OS"})," project is a Kubernetes-based personal OS. It embeds LlamaEdge to power AI services such as local search and document QA."]}),"\n"]})]})}function m(e={}){const{wrapper:a}={...(0,n.R)(),...e.components};return a?(0,o.jsx)(a,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,a,s)=>{s.d(a,{R:()=>t,x:()=>r});var o=s(6540);const n={},l=o.createContext(n);function t(e){const a=o.useContext(l);return o.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:t(e.components),o.createElement(l.Provider,{value:a},e.children)}}}]);