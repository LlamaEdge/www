"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8581],{5610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"LlamaEdge","href":"/docs/intro","docId":"intro","unlisted":false},{"type":"link","label":"LlamaEdge vs Python","href":"/docs/llamaedge_vs_python","docId":"llamaedge_vs_python","unlisted":false},{"type":"link","label":"LlamaEdge vs llama.cpp","href":"/docs/llamaedge_vs_llamacpp","docId":"llamaedge_vs_llamacpp","unlisted":false},{"type":"link","label":"LlamaEdge vs Ollama","href":"/docs/llamaedge_vs_ollama","docId":"llamaedge_vs_ollama","unlisted":false},{"type":"category","label":"User Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"LlamaEdge","href":"/docs/user-guide/","docId":"user-guide/index","unlisted":false},{"type":"category","label":"LLM","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Quick start with LLM models","href":"/docs/user-guide/llm/get-started-with-llamaedge","docId":"user-guide/llm/get-started-with-llamaedge","unlisted":false},{"type":"link","label":"Start an OpenAI compatible API server","href":"/docs/user-guide/llm/full-openai","docId":"user-guide/llm/full-openai","unlisted":false},{"type":"link","label":"Calling external tools","href":"/docs/user-guide/llm/tool-call","docId":"user-guide/llm/tool-call","unlisted":false},{"type":"link","label":"API Reference","href":"/docs/user-guide/llm/api-reference","docId":"user-guide/llm/api-reference","unlisted":false},{"type":"category","label":"Long-term memory and knowledge","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Long-term memory for the LLM","href":"/docs/user-guide/llm/server-side-rag/quick-start","docId":"user-guide/llm/server-side-rag/quick-start","unlisted":false},{"type":"link","label":"Knowledge base from a plain text file","href":"/docs/user-guide/llm/server-side-rag/text","docId":"user-guide/llm/server-side-rag/text","unlisted":false},{"type":"link","label":"Knowledge base from a markdown file","href":"/docs/user-guide/llm/server-side-rag/markdown","docId":"user-guide/llm/server-side-rag/markdown","unlisted":false},{"type":"link","label":"Use the API server","href":"/docs/user-guide/llm/server-side-rag/rag-service","docId":"user-guide/llm/server-side-rag/rag-service","unlisted":false}],"href":"/docs/category/long-term-memory-and-knowledge"}],"href":"/docs/category/llm"},{"type":"category","label":"Speech to Text","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Quick Start with Whisper","href":"/docs/user-guide/speech-to-text/quick-start-whisper","docId":"user-guide/speech-to-text/quick-start-whisper","unlisted":false},{"type":"link","label":"The API server CLI options","href":"/docs/user-guide/speech-to-text/cli","docId":"user-guide/speech-to-text/cli","unlisted":false},{"type":"link","label":"API Reference","href":"/docs/user-guide/speech-to-text/api-reference","docId":"user-guide/speech-to-text/api-reference","unlisted":false}],"href":"/docs/category/speech-to-text"},{"type":"category","label":"Text to Image","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Quick Start with Stable Diffusion models","href":"/docs/user-guide/text-to-image/quick-start-sd","docId":"user-guide/text-to-image/quick-start-sd","unlisted":false},{"type":"link","label":"Run FLUX models with LlamaEdge","href":"/docs/user-guide/text-to-image/flux","docId":"user-guide/text-to-image/flux","unlisted":false}],"href":"/docs/category/text-to-image"},{"type":"category","label":"Text to Speech","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Run GPT-Sovits with LlamaEdge","href":"/docs/user-guide/text-to-speech/gpt-sovits","docId":"user-guide/text-to-speech/gpt-sovits","unlisted":false}],"href":"/docs/category/text-to-speech"},{"type":"category","label":"Multimodal","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Quick start with the Llava mdoels","href":"/docs/user-guide/multimodal/llava","docId":"user-guide/multimodal/llava","unlisted":false}],"href":"/docs/category/multimodal"},{"type":"category","label":"Ecosystem apps","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Start an LlamaEdge API service","href":"/docs/user-guide/openai-api/intro","docId":"user-guide/openai-api/intro","unlisted":false},{"type":"link","label":"LobeChat","href":"/docs/user-guide/openai-api/lobechat","docId":"user-guide/openai-api/lobechat","unlisted":false},{"type":"link","label":"AI coding assistant: Continue","href":"/docs/user-guide/openai-api/continue","docId":"user-guide/openai-api/continue","unlisted":false},{"type":"link","label":"Obsidian","href":"/docs/user-guide/openai-api/obsidian","docId":"user-guide/openai-api/obsidian","unlisted":false},{"type":"link","label":"FlowiseAI tool call","href":"/docs/user-guide/openai-api/flowiseai-tool-call","docId":"user-guide/openai-api/flowiseai-tool-call","unlisted":false},{"type":"link","label":"Translation Agent","href":"/docs/user-guide/openai-api/translation-agent","docId":"user-guide/openai-api/translation-agent","unlisted":false},{"type":"link","label":"LangChain","href":"/docs/user-guide/openai-api/langchain","docId":"user-guide/openai-api/langchain","unlisted":false},{"type":"link","label":"Agent Zero","href":"/docs/user-guide/openai-api/agent-zero","docId":"user-guide/openai-api/agent-zero","unlisted":false}],"href":"/docs/category/ecosystem-apps"},{"type":"link","label":"Use LlamaEdge in Docker","href":"/docs/user-guide/llamaedge-docker","docId":"user-guide/llamaedge-docker","unlisted":false},{"type":"link","label":"Use LlamaEdge in Kubernetes","href":"/docs/user-guide/llamaedge-kubernetes","docId":"user-guide/llamaedge-kubernetes","unlisted":false}],"href":"/docs/category/user-guide"},{"type":"category","label":"Developer Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Create a basic LLM app","href":"/docs/developer-guide/basic-llm-app","docId":"developer-guide/basic-llm-app","unlisted":false},{"type":"link","label":"Create a chatbot LLM app","href":"/docs/developer-guide/chatbot-llm-app","docId":"developer-guide/chatbot-llm-app","unlisted":false},{"type":"link","label":"Create a multimodal app","href":"/docs/developer-guide/multimodal-app","docId":"developer-guide/multimodal-app","unlisted":false},{"type":"link","label":"Create an embedding app","href":"/docs/developer-guide/embedding-app","docId":"developer-guide/embedding-app","unlisted":false},{"type":"link","label":"Create knowledge embeddings using the API server","href":"/docs/developer-guide/create-embeddings-collection","docId":"developer-guide/create-embeddings-collection","unlisted":false},{"type":"link","label":"Implement your own RAG API server","href":"/docs/developer-guide/rag-api-server","docId":"developer-guide/rag-api-server","unlisted":false}],"href":"/docs/category/developer-guide"}]},"docs":{"developer-guide/basic-llm-app":{"id":"developer-guide/basic-llm-app","title":"Create a basic LLM app","description":"At the most basic level, the LLM completes text. That is why the input text is called a \\"prompt\\". The base model simply comes up with the next words that are likely to follow the prompt. In this example, we will demonstrate this basic use case.","sidebar":"tutorialSidebar"},"developer-guide/chatbot-llm-app":{"id":"developer-guide/chatbot-llm-app","title":"Create a chatbot LLM app","description":"The most common LLM app has to be the chatbot. For that, the base LLM is finetuned with a lot of back and forth conversation examples. The base LLM \\"learns\\" how to follow conversations and becomes a chat LLM. Since the conversation examples are fed into the LLM using certain formats, the chat LLM will expect the input prompt to follow the same format. This is called the prompt template. Let\'s see how that works.","sidebar":"tutorialSidebar"},"developer-guide/create-embeddings-collection":{"id":"developer-guide/create-embeddings-collection","title":"Create knowledge embeddings using the API server","description":"The LlamaEdge API server project demonstrates how to support OpenAI style APIs to upload, chunck, and create embeddings for a text document. In this guide, I will show you how to use those API endpoints as a developer.","sidebar":"tutorialSidebar"},"developer-guide/embedding-app":{"id":"developer-guide/embedding-app","title":"Create an embedding app","description":"An important LLM task is to generate embeddings for natural language sentences. It converts a sentence to a vector of numbers called an \\"embedding\\". The embedding vectors can then be stored in a vector database. You can search it later to find similiar sentences.","sidebar":"tutorialSidebar"},"developer-guide/multimodal-app":{"id":"developer-guide/multimodal-app","title":"Create a multimodal app","description":"Coming soon.","sidebar":"tutorialSidebar"},"developer-guide/rag-api-server":{"id":"developer-guide/rag-api-server","title":"Implement your own RAG API server","description":"Coming soon.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"LlamaEdge","description":"LlamaEdge is the easiest & fastest way to run customized and fine-tuned LLMs locally or on the edge.","sidebar":"tutorialSidebar"},"llamaedge_vs_llamacpp":{"id":"llamaedge_vs_llamacpp","title":"LlamaEdge vs llama.cpp","description":"The llama.cpp project is one of the inference backends for LlamaEdge. LlamaEdge provides high level application","sidebar":"tutorialSidebar"},"llamaedge_vs_ollama":{"id":"llamaedge_vs_ollama","title":"LlamaEdge vs Ollama","description":"There are several popular tools to run \\"local LLMs\\". Ollama is one of the earlist and most popular. Why do people","sidebar":"tutorialSidebar"},"llamaedge_vs_python":{"id":"llamaedge_vs_python","title":"LlamaEdge vs Python","description":"Most AI models are trained and even finetuned in Python / PyTorch, but you should not deploy and run them in Python.","sidebar":"tutorialSidebar"},"user-guide/index":{"id":"user-guide/index","title":"LlamaEdge","description":"LlamaEdge is a versatile platform supporting multiple types of AI models and applications:","sidebar":"tutorialSidebar"},"user-guide/llamaedge-docker":{"id":"user-guide/llamaedge-docker","title":"Use LlamaEdge in Docker","description":"You can run all the commands in this document without any change on any machine with the latest Docker and at least 8GB of RAM available to the container.","sidebar":"tutorialSidebar"},"user-guide/llamaedge-kubernetes":{"id":"user-guide/llamaedge-kubernetes","title":"Use LlamaEdge in Kubernetes","description":"Coming soon.","sidebar":"tutorialSidebar"},"user-guide/llm/api-reference":{"id":"user-guide/llm/api-reference","title":"API Reference","description":"Introduction","sidebar":"tutorialSidebar"},"user-guide/llm/full-openai":{"id":"user-guide/llm/full-openai","title":"Start an OpenAI compatible API server","description":"LlamaEdge support running LLMs along with embbedding models, allowing you to start a drop-in replacement for OpenAI API.","sidebar":"tutorialSidebar"},"user-guide/llm/get-started-with-llamaedge":{"id":"user-guide/llm/get-started-with-llamaedge","title":"Quick start with LLM models","description":"LlamaEdge is a suite of component libraries and command line tools for developers to embed and run LLMs in their own apps. The best way to quickly experience LlamaEdge is to use easy-to-use utilities built on top of it.","sidebar":"tutorialSidebar"},"user-guide/llm/server-side-rag/markdown":{"id":"user-guide/llm/server-side-rag/markdown","title":"Knowledge base from a markdown file","description":"In this section, we will discuss how to create a vector collection snapshot from a markdown file. The","sidebar":"tutorialSidebar"},"user-guide/llm/server-side-rag/quick-start":{"id":"user-guide/llm/server-side-rag/quick-start","title":"Long-term memory for the LLM","description":"The LLM app requires both long-term and short-term memories. Long-term memory includes factual knowledge, historical facts, background stories etc. They are best added to the context as complete chapters instead of small chunks of text to maintain the internal consistency of the knowledge.","sidebar":"tutorialSidebar"},"user-guide/llm/server-side-rag/rag-service":{"id":"user-guide/llm/server-side-rag/rag-service","title":"Use the API server","description":"The LlamaEdge RAG API server provides an API endpoint /create/rag that takes a text file, segments it into small chunks, turns the chunks into embeddings (i.e., vectors), and then stores the embeddings into the Qdrant database.","sidebar":"tutorialSidebar"},"user-guide/llm/server-side-rag/text":{"id":"user-guide/llm/server-side-rag/text","title":"Knowledge base from a plain text file","description":"In this section, we will discuss how to create a vector collection snapshot from a plain text file. The","sidebar":"tutorialSidebar"},"user-guide/llm/tool-call":{"id":"user-guide/llm/tool-call","title":"Calling external tools","description":"Tool calling is one of the truly \\"LLM native\\" interaction modes that has never existed before.","sidebar":"tutorialSidebar"},"user-guide/multimodal/llava":{"id":"user-guide/multimodal/llava","title":"Quick start with the Llava mdoels","description":"","sidebar":"tutorialSidebar"},"user-guide/openai-api/agent-zero":{"id":"user-guide/openai-api/agent-zero","title":"Agent Zero","description":"Agent Zero is a general purpose AI agent application. You can simply ask it to accomplish tasks on the command line.","sidebar":"tutorialSidebar"},"user-guide/openai-api/continue":{"id":"user-guide/openai-api/continue","title":"AI coding assistant: Continue","description":"Continue is the leading open-source AI code assistant.","sidebar":"tutorialSidebar"},"user-guide/openai-api/flowiseai-tool-call":{"id":"user-guide/openai-api/flowiseai-tool-call","title":"FlowiseAI tool call","description":"FlowiseAI is a low-code tool for developers to build customized LLM orchestration flows & AI agents.","sidebar":"tutorialSidebar"},"user-guide/openai-api/intro":{"id":"user-guide/openai-api/intro","title":"Start an LlamaEdge API service","description":"Since LlamaEdge provides an OpenAI-compatible API service, it can be a drop-in replacement for OpenAI in almost all LLM applications and frameworks.","sidebar":"tutorialSidebar"},"user-guide/openai-api/langchain":{"id":"user-guide/openai-api/langchain","title":"LangChain","description":"In this tutorial, I will introduce you how to build a client-side RAG using Llama2-7b-chat model, based on LlamaEdge and Langchain.","sidebar":"tutorialSidebar"},"user-guide/openai-api/lobechat":{"id":"user-guide/openai-api/lobechat","title":"LobeChat","description":"The LobeChat framework is a modern chatbot framework that supports a wide range of","sidebar":"tutorialSidebar"},"user-guide/openai-api/obsidian":{"id":"user-guide/openai-api/obsidian","title":"Obsidian","description":"Obsidian is a note-taking application that enables users to create, link, and visualize ideas directly on their devices. With Obsidian, you can seamlessly sync notes across devices, publish your work, and collaborate with others. The app is highly customizable, allowing users to enhance functionality through a wide range of plugins and themes. Its unique features include a graph view to visualize connections between notes, making it ideal for managing complex information and fostering creativity. Obsidian also emphasizes data privacy by storing notes locally.","sidebar":"tutorialSidebar"},"user-guide/openai-api/translation-agent":{"id":"user-guide/openai-api/translation-agent","title":"Translation Agent","description":"This LLM Translation Agent originally built by Prof. Andrew Ng is designed to facilitate accurate and efficient translation across multiple languages. It employs open source LLMs (Large Language Models) to provide high-quality translations. You can use your own fine-tuned models or any LLMs on Hugging Face like Meta\'s Llama 3. This documentation shows how the Transgenic Agent utilizes the Gemma-2-9B model for translation.","sidebar":"tutorialSidebar"},"user-guide/speech-to-text/api-reference":{"id":"user-guide/speech-to-text/api-reference","title":"API Reference","description":"","sidebar":"tutorialSidebar"},"user-guide/speech-to-text/cli":{"id":"user-guide/speech-to-text/cli","title":"The API server CLI options","description":"","sidebar":"tutorialSidebar"},"user-guide/speech-to-text/quick-start-whisper":{"id":"user-guide/speech-to-text/quick-start-whisper","title":"Quick Start with Whisper","description":"Whisper is OpenAI\'s general-purpose speech recognition model that accurately converts speech to text. This guide shows you how to set up and run Whisper using the LlamaEdge whisper API server server, which provides an OpenAI-compatible API interface.","sidebar":"tutorialSidebar"},"user-guide/text-to-image/flux":{"id":"user-guide/text-to-image/flux","title":"Run FLUX models with LlamaEdge","description":"FLUX.1 is an open-source image generation model developed by Black Forest Labs, the creators of Stable Diffusion. With the LlamaEdge stable-diffusion-api-server, you can build an OpenAI-compatible API server for FLUX models.","sidebar":"tutorialSidebar"},"user-guide/text-to-image/quick-start-sd":{"id":"user-guide/text-to-image/quick-start-sd","title":"Quick Start with Stable Diffusion models","description":"Stable Diffusion is a state-of-the-art text-to-image generation model that creates high-quality images from text descriptions. With the LlamaEdge stable-diffusion-api-server, you can build an OpenAI-compatible API server for Stable Diffusion models.","sidebar":"tutorialSidebar"},"user-guide/text-to-speech/gpt-sovits":{"id":"user-guide/text-to-speech/gpt-sovits","title":"Run GPT-Sovits with LlamaEdge","description":"","sidebar":"tutorialSidebar"}}}')}}]);