"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[805],{836:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>r,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var t=a(4848),s=a(8453);const o={sidebar_position:3},i="Quick start with the Gemma-3 model",l={id:"ai-models/multimodal/gemma-3",title:"Quick start with the Gemma-3 model",description:"Gemma 3 introduces powerful vision-language capabilities across its 4B, 12B, and 27B models through a custom SigLIP vision encoder, enabling rich interpretation of visual input. It processes fixed-size 896x896 images using a \u201cPan&Scan\u201d algorithm for adaptive cropping and resizing, balancing detail preservation with computational cost",source:"@site/docs/ai-models/multimodal/gemma-3.md",sourceDirName:"ai-models/multimodal",slug:"/ai-models/multimodal/gemma-3",permalink:"/docs/ai-models/multimodal/gemma-3",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ai-models/multimodal/gemma-3.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Quick start with the Qwen 2.5 VL model",permalink:"/docs/ai-models/multimodal/qwen2-5"},next:{title:"Quick start with the MedGemma-4b model",permalink:"/docs/ai-models/multimodal/medgemma-4b"}},r={},c=[{value:"Step 1: Install WasmEdge",id:"step-1-install-wasmedge",level:3},{value:"Step 2: Download the LLM model",id:"step-2-download-the-llm-model",level:3},{value:"Step 3: Download a portable API server app",id:"step-3-download-a-portable-api-server-app",level:3},{value:"Step 4: Chat with the chatbot UI",id:"step-4-chat-with-the-chatbot-ui",level:3},{value:"Step 5: Send an API request",id:"step-5-send-an-api-request",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h3:"h3",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"quick-start-with-the-gemma-3-model",children:"Quick start with the Gemma-3 model"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",children:"Gemma 3"})," introduces powerful vision-language capabilities across its 4B, 12B, and 27B models through a custom SigLIP vision encoder, enabling rich interpretation of visual input. It processes fixed-size 896x896 images using a \u201cPan&Scan\u201d algorithm for adaptive cropping and resizing, balancing detail preservation with computational cost"]}),"\n",(0,t.jsx)(n.h3,{id:"step-1-install-wasmedge",children:"Step 1: Install WasmEdge"}),"\n",(0,t.jsx)(n.p,{children:"First off, you'll need WasmEdge, a high-performance, lightweight, and cross-platform LLM runtime."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install_v2.sh | bash -s\n"})}),"\n",(0,t.jsx)(n.h3,{id:"step-2-download-the-llm-model",children:"Step 2: Download the LLM model"}),"\n",(0,t.jsxs)(n.p,{children:["Next, you'll need to obtain model files: the ",(0,t.jsx)(n.strong,{children:"Gemma-3 model"})," and the ",(0,t.jsx)(n.strong,{children:"mmproj model"}),"."]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"The Gemma-3-1B model is a small-scale language-only model and does not support vision-language capabilities"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"curl -LO https://huggingface.co/second-state/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-Q5_K_M.gguf\ncurl -LO https://huggingface.co/second-state/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-mmproj-f16.gguf\n"})}),"\n",(0,t.jsx)(n.h3,{id:"step-3-download-a-portable-api-server-app",children:"Step 3: Download a portable API server app"}),"\n",(0,t.jsxs)(n.p,{children:["Next, you need an application that can build and OpenAI-compatible API server for the Gemma-3 models\nThe ",(0,t.jsx)(n.a,{href:"https://github.com/LlamaEdge/LlamaEdge/tree/main/llama-api-server",children:"LlamaEdge api server app"})," is a lightweight and cross-platform Wasm app that works on any device\nyou might have. Just download the compiled binary app."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"curl -LO https://github.com/second-state/LlamaEdge/releases/latest/download/llama-api-server.wasm\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["The version of the ",(0,t.jsx)(n.code,{children:"llama-api-server.wasm"})," should be v0.18.5 and above."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-4-chat-with-the-chatbot-ui",children:"Step 4: Chat with the chatbot UI"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"llama-api-server.wasm"})," is a web server with an OpenAI-compatible API. You still need HTML files for the chatbot UI. It's optional and you can use ",(0,t.jsx)(n.code,{children:"curl"})," to send an API request.\nDownload and unzip the HTML UI files as follows."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"curl -LO https://github.com/LlamaEdge/chatbot-ui/releases/latest/download/chatbot-ui.tar.gz\ntar xzf chatbot-ui.tar.gz\nrm chatbot-ui.tar.gz\n"})}),"\n",(0,t.jsx)(n.p,{children:"Then, start the web server."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"wasmedge --dir .:. --nn-preload default:GGML:AUTO:gemma-3-4b-it-Q5_K_M.gguf \\\n  llama-api-server.wasm \\\n  --prompt-template gemma-3 \\\n  --llava-mmproj gemma-3-4b-it-mmproj-f16.gguf \\\n  --ctx-size 4096 \\\n  --model-name gemma-3-4b\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"The above command line works on a Macbook with 16 GB memory."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Upon successful execution, you should see output similar to the following:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[2025-05-18 11:23:09.970] [info] llama_api_server in llama-api-server/src/main.rs:202: LOG LEVEL: info\n[2025-05-18 11:23:09.973] [info] llama_api_server in llama-api-server/src/main.rs:205: SERVER VERSION: 0.18.5\n[2025-05-18 11:23:09.976] [info] llama_api_server in llama-api-server/src/main.rs:544: model_name: Qwen2.5-VL-7B-Instruct\n\n...\n\n[2025-05-18 11:23:10.531] [info] llama_api_server in llama-api-server/src/main.rs:917: plugin_ggml_version: b5361 (commit cf0a43bb)\n[2025-05-18 11:23:10.533] [info] llama_api_server in llama-api-server/src/main.rs:952: Listening on 0.0.0.0:8080\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Then, go to ",(0,t.jsx)(n.code,{children:"http://localhost:8080"})," on your computer to access the chatbot UI on a web page! You can upload an imange and chat with the model based on the image."]}),"\n",(0,t.jsx)(n.h3,{id:"step-5-send-an-api-request",children:"Step 5: Send an API request"}),"\n",(0,t.jsxs)(n.p,{children:["You can send an API request to call the model, which is more universal. The following command demonstrates how to send a CURL request to llama-api-server. The request includes a base64-encoded string of an image in the ",(0,t.jsx)(n.code,{children:"image_url"})," field. For demonstration purposes, only a portion of the base64 string is shown here. In practice, you should use the complete base64 string."]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["[!TIP]\n",(0,t.jsx)(n.a,{href:"https://base64.guru/converter/encode/image/jpg",children:"base64.guru"})," provides a tool for encoding JPG to Base64."]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'curl --location \'http://localhost:8080/v1/chat/completions\' \\\n--header \'Content-Type: application/json\' \\\n--data \'{\n    "messages": [\n        {\n            "role": "system",\n            "content": "You are a helpful assistant that accurately describes the content of images provided by the user."\n        },\n        {\n            "content": [\n                {\n                    "type": "text",\n                    "text": "Describe the picture"\n                },\n                {\n                    "type": "image_url",\n                    "image_url": {\n                        "url": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgFBgcGBQg......X/VaTer/ALzOU/Lg1XMiLMuR3EWMb77/AHsD/DNTIhXPnmvLmwj"\n                    }\n                }\n            ],\n            "role": "user"\n        }\n    ],\n    "model": "gemma-3-4b"\n}\'\n'})}),"\n",(0,t.jsx)(n.p,{children:"If the request is processed successfully, you will receive a response similar to the following:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'{\n    "id": "chatcmpl-e5f777db-c913-45ab-b37f-e2c499c8fa0b",\n    "object": "chat.completion",\n    "created": 1747652210,\n    "model": "gemma-3-4b",\n    "choices": [\n        {\n            "index": 0,\n            "message": {\n                "content": "mixed berries in a paper bowl",\n                "role": "assistant"\n            },\n            "finish_reason": "stop",\n            "logprobs": null\n        }\n    ],\n    "usage": {\n        "prompt_tokens": 27,\n        "completion_tokens": 8,\n        "total_tokens": 35\n    }\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"You can also combine the base64 conversion and API call into a single command like this:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'curl --location \'http://localhost:8080/v1/chat/completions\' \\\n--header \'Content-Type: application/json\' \\\n--data \'{"messages": [{"role": "system","content": "You are a helpful assistant that accurately describes the content of images provided by the user."}, {"content": [{"type": "text","text": "Tell me the history of this place"},{"type": "image_url","image_url": {"url": "\'"$(base64 -i /path/to/image.jpg)"\'"}}], "role": "user"}], "model": "gemma-3-4b"}\'\n'})}),"\n",(0,t.jsx)(n.p,{children:"Congratulations! You have now started an multimodal app on your own device."})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>i,x:()=>l});var t=a(6540);const s={},o=t.createContext(s);function i(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);