"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7925],{6008:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>r,toc:()=>d});var t=n(4848),s=n(8453);const o={sidebar_position:4},i="Quick start with the MedGemma-4b model",r={id:"user-guide/multimodal/medgemma-4b",title:"Quick start with the MedGemma-4b model",description:"MedGemma-4b  is a collection of Gemma 3 variants that are trained for performance on medical text and image comprehension. Developers can use MedGemma to accelerate building healthcare-based AI applications. MedGemma currently comes in two variants: a 4B multimodal version and a 27B text-only version.",source:"@site/docs/user-guide/multimodal/medgemma-4b.md",sourceDirName:"user-guide/multimodal",slug:"/user-guide/multimodal/medgemma-4b",permalink:"/docs/user-guide/multimodal/medgemma-4b",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/user-guide/multimodal/medgemma-4b.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Quick start with the Gemma-3 model",permalink:"/docs/user-guide/multimodal/gemma-3"},next:{title:"Ecosystem apps",permalink:"/docs/category/ecosystem-apps"}},l={},d=[{value:"Step 1: Install WasmEdge",id:"step-1-install-wasmedge",level:3},{value:"Step 2: Download the LLM model",id:"step-2-download-the-llm-model",level:3},{value:"Step 3: Download a portable API server app",id:"step-3-download-a-portable-api-server-app",level:3},{value:"Step 4: Chat with the chatbot UI",id:"step-4-chat-with-the-chatbot-ui",level:3},{value:"Step 5: Send an API request",id:"step-5-send-an-api-request",level:3}];function m(e){const a={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h3:"h3",img:"img",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.h1,{id:"quick-start-with-the-medgemma-4b-model",children:"Quick start with the MedGemma-4b model"}),"\n",(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.a,{href:"https://huggingface.co/second-state/medgemma-4b-it-GGUF",children:"MedGemma-4b"}),"  is a collection of Gemma 3 variants that are trained for performance on medical text and image comprehension. Developers can use MedGemma to accelerate building healthcare-based AI applications. MedGemma currently comes in two variants: a 4B multimodal version and a 27B text-only version."]}),"\n",(0,t.jsx)(a.h3,{id:"step-1-install-wasmedge",children:"Step 1: Install WasmEdge"}),"\n",(0,t.jsx)(a.p,{children:"First off, you'll need WasmEdge, a high-performance, lightweight, and cross-platform LLM runtime."}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install_v2.sh | bash -s\n"})}),"\n",(0,t.jsx)(a.h3,{id:"step-2-download-the-llm-model",children:"Step 2: Download the LLM model"}),"\n",(0,t.jsxs)(a.p,{children:["Next, you'll need to obtain model files: the ",(0,t.jsx)(a.strong,{children:"MedGemma model"})," and the ",(0,t.jsx)(a.strong,{children:"mmproj model"}),"."]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"curl -LO https://huggingface.co/second-state/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q5_K_M.gguf\ncurl -LO https://huggingface.co/second-state/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-mmproj-f16.gguf\n"})}),"\n",(0,t.jsx)(a.h3,{id:"step-3-download-a-portable-api-server-app",children:"Step 3: Download a portable API server app"}),"\n",(0,t.jsxs)(a.p,{children:["Next, you need an application that can build and OpenAI-compatible API server for the MedGemma models\nThe ",(0,t.jsx)(a.a,{href:"https://github.com/LlamaEdge/LlamaEdge/tree/main/llama-api-server",children:"LlamaEdge api server app"})," is a lightweight and cross-platform Wasm app that works on any device\nyou might have. Just download the compiled binary app."]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"curl -LO https://github.com/second-state/LlamaEdge/releases/latest/download/llama-api-server.wasm\n"})}),"\n",(0,t.jsxs)(a.blockquote,{children:["\n",(0,t.jsxs)(a.p,{children:["The version of the ",(0,t.jsx)(a.code,{children:"llama-api-server.wasm"})," should be v0.18.5 and above."]}),"\n"]}),"\n",(0,t.jsx)(a.h3,{id:"step-4-chat-with-the-chatbot-ui",children:"Step 4: Chat with the chatbot UI"}),"\n",(0,t.jsxs)(a.p,{children:["The ",(0,t.jsx)(a.code,{children:"llama-api-server.wasm"})," is a web server with an OpenAI-compatible API. You still need HTML files for the chatbot UI. It's optional and you can use ",(0,t.jsx)(a.code,{children:"curl"})," to send an API request.\nDownload and unzip the HTML UI files as follows."]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"curl -LO https://github.com/LlamaEdge/chatbot-ui/releases/latest/download/chatbot-ui.tar.gz\ntar xzf chatbot-ui.tar.gz\nrm chatbot-ui.tar.gz\n"})}),"\n",(0,t.jsx)(a.p,{children:"Then, start the web server."}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"wasmedge --dir .:. --nn-preload default:GGML:AUTO:medgemma-4b-it-Q5_K_M.gguf \\\n  llama-api-server.wasm \\\n  --prompt-template gemma-3 \\\n  --llava-mmproj medgemma-4b-it-mmproj-f16.gguf \\\n  --ctx-size 4098 \\\n  --model-name medgemma-4b\n\n"})}),"\n",(0,t.jsxs)(a.blockquote,{children:["\n",(0,t.jsx)(a.p,{children:"The above command lines work on a Macbook with 16 GB memory."}),"\n"]}),"\n",(0,t.jsx)(a.p,{children:"Upon successful execution, you should see output similar to the following:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{children:"[2025-05-29 17:07:46.398] [info] llama_api_server in llama-api-server/src/main.rs:544: model_name: medgemma-4b\n[2025-05-29 17:07:46.398] [info] llama_api_server in llama-api-server/src/main.rs:553: model_alias: default\n[2025-05-29 17:07:46.398] [info] llama_api_server in llama-api-server/src/main.rs:573: ctx_size: 4098\n[2025-05-29 17:07:46.398] [info] llama_api_server in llama-api-server/src/main.rs:593: batch_size: 512\n\n...\n[2025-05-29 17:07:46.935] [info] llama_api_server in llama-api-server/src/main.rs:907: running_mode: chat\n[2025-05-29 17:07:46.935] [info] llama_api_server in llama-api-server/src/main.rs:917: plugin_ggml_version: b5201 (commit 85f36e5e)\n[2025-05-29 17:07:46.936] [info] llama_api_server in llama-api-server/src/main.rs:952: Listening on 0.0.0.0:8080\n"})}),"\n",(0,t.jsxs)(a.p,{children:["Then, go to ",(0,t.jsx)(a.code,{children:"http://localhost:8080"})," on your computer to access the chatbot UI on a web page! You can upload an imange and chat with the model based on the medical image."]}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.img,{src:n(2591).A+"",width:"1258",height:"1728"})}),"\n",(0,t.jsx)(a.h3,{id:"step-5-send-an-api-request",children:"Step 5: Send an API request"}),"\n",(0,t.jsxs)(a.p,{children:["You can send an API request to call the model, which is more universal. The following command demonstrates how to send a CURL request to llama-api-server. The request includes a base64-encoded string of an image in the ",(0,t.jsx)(a.code,{children:"image_url"})," field. For demonstration purposes, only a portion of the base64 string is shown here. In practice, you should use the complete base64 string."]}),"\n",(0,t.jsxs)(a.blockquote,{children:["\n",(0,t.jsxs)(a.p,{children:["[!TIP]\n",(0,t.jsx)(a.a,{href:"https://base64.guru/converter/encode/image/jpg",children:"base64.guru"})," provides a tool for encoding JPG to Base64."]}),"\n"]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-bash",children:'curl --location \'http://localhost:8080/v1/chat/completions\' \\\n--header \'Content-Type: application/json\' \\\n--data \'{\n    "messages": [\n        {\n            "role": "system",\n            "content": "You are a helpful medical assistant that accurately describes the content of images provided by the user."\n        },\n        {\n            "content": [\n                {\n                    "type": "text",\n                    "text": "Read this chest X-ray and find anything abnormal"\n                },\n                {\n                    "type": "image_url",\n                    "image_url": {\n                        "url": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgFBgcGBQg......X/VaTer/ALzOU/Lg1XMiLMuR3EWMb77/AHsD/DNTIhXPnmvLmwj"\n                    }\n                }\n            ],\n            "role": "user"\n        }\n    ],\n    "model": "medgemma-4b"\n}\'\n'})}),"\n",(0,t.jsx)(a.p,{children:"If the request is processed successfully, you will receive a response similar to the following:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-bash",children:'{\n    "id": "chatcmpl-e5f777db-c913-45ab-b37f-e2c499c8fa0b",\n    "object": "chat.completion",\n    "created": 1747652210,\n    "model": "medgemma-4b",\n    "choices": [\n        {\n            "index": 0,\n            "message": {\n                "content": "There is a round, dense opacity in the right lower lobe of the lung. This could be a mass or nodule, and further investigation would be needed to determine its nature.",\n                "role": "assistant"\n            },\n            "finish_reason": "stop",\n            "logprobs": null\n        }\n    ],\n    "usage": {\n        "prompt_tokens": 27,\n        "completion_tokens": 68,\n        "total_tokens": 95\n    }\n}\n'})}),"\n",(0,t.jsx)(a.p,{children:"You can also combine the base64 conversion and API call into a single command like this:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-bash",children:'curl --location \'http://localhost:8080/v1/chat/completions\' \\\n--header \'Content-Type: application/json\' \\\n--data \'{"messages": [{"role": "system","content": "You are a helpful medical assistant that accurately describes the content of images provided by the user."}, {"content": [{"type": "text","text": ""Read this chest X-ray and find anything abnormal"},{"type": "image_url","image_url": {"url": "\'"$(base64 -i /path/to/image.jpg)"\'"}}], "role": "user"}], "model": "medgemma-4b"}\'\n'})}),"\n",(0,t.jsx)(a.p,{children:"Congratulations! You have now started an multimodal app on your own device."})]})}function c(e={}){const{wrapper:a}={...(0,s.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(m,{...e})}):m(e)}},2591:(e,a,n)=>{n.d(a,{A:()=>t});const t=n.p+"assets/images/medgemma-90a0e37dede4921e743d9bae195af46d.jpg"},8453:(e,a,n)=>{n.d(a,{R:()=>i,x:()=>r});var t=n(6540);const s={},o=t.createContext(s);function i(e){const a=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(o.Provider,{value:a},e.children)}}}]);