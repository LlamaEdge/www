"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3216],{1148:(e,s,a)=>{a.r(s),a.d(s,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});var t=a(4848),n=a(8453);const l={sidebar_position:2},r="Manage Your API Services with Llama-Nexus",i={id:"llama-nexus/quick-start",title:"Manage Your API Services with Llama-Nexus",description:"This tutorial shows you how to use Llama-Nexus to manage multiple OpenAI-compatible API services.",source:"@site/docs/llama-nexus/quick-start.md",sourceDirName:"llama-nexus",slug:"/llama-nexus/quick-start",permalink:"/docs/llama-nexus/quick-start",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/llama-nexus/quick-start.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"What is Llama-Nexus",permalink:"/docs/llama-nexus/"},next:{title:"Register API services",permalink:"/docs/llama-nexus/register"}},o={},c=[{value:"Install the Llama-Nexus software",id:"install-the-llama-nexus-software",level:2},{value:"Start Llama-Nexus",id:"start-llama-nexus",level:2},{value:"Register a chat service",id:"register-a-chat-service",level:2},{value:"Call the service",id:"call-the-service",level:2}];function u(e){const s={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",strong:"strong",...(0,n.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.h1,{id:"manage-your-api-services-with-llama-nexus",children:"Manage Your API Services with Llama-Nexus"}),"\n",(0,t.jsxs)(s.p,{children:["This tutorial shows you how to use ",(0,t.jsx)(s.strong,{children:"Llama-Nexus"})," to manage multiple OpenAI-compatible API services."]}),"\n",(0,t.jsx)(s.h2,{id:"install-the-llama-nexus-software",children:"Install the Llama-Nexus software"}),"\n",(0,t.jsx)(s.p,{children:"The following command installs the Linux on x86 version of llama-nexus."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"curl -LO https://github.com/LlamaEdge/llama-nexus/releases/latest/download/llama-nexus-unknown-linux-gnu-x86_64.tar.gz\n\ntar xvf llama-nexus-unknown-linux-gnu-x86_64.tar\n"})}),"\n",(0,t.jsxs)(s.blockquote,{children:["\n",(0,t.jsxs)(s.p,{children:["Download for your platfrom here: ",(0,t.jsx)(s.a,{href:"https://github.com/LlamaEdge/llama-nexus/releases/",children:"https://github.com/LlamaEdge/llama-nexus/releases/"})]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"start-llama-nexus",children:"Start Llama-Nexus"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"./llama-nexus --config config.toml\n"})}),"\n",(0,t.jsxs)(s.p,{children:["By default, Llama-Nexus listens on port ",(0,t.jsx)(s.code,{children:"3389"}),"."]}),"\n",(0,t.jsx)(s.h2,{id:"register-a-chat-service",children:"Register a chat service"}),"\n",(0,t.jsx)(s.p,{children:"Assuming you already have an OpenAI-compatible API server for your LLM, let\u2018s register it with Llama-Nexus."}),"\n",(0,t.jsxs)(s.p,{children:["If you'd like to run a model locally, refer to the ",(0,t.jsx)(s.a,{href:"/docs/ai-models/llm/quick-start-llm",children:"Quick Start with LLM"})," guide."]}),"\n",(0,t.jsxs)(s.p,{children:["Register the LLM chat API server for the ",(0,t.jsx)(s.code,{children:"/chat/completions"})," endpoint:"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"curl --location 'http://localhost:3389/admin/servers/register' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer YOUR_API_KEY_GOES_HERE' \\\n--data '{\n    \"url\": \"http://localhost:8080/v1\",\n    \"kind\": \"chat\"\n}'\n"})}),"\n",(0,t.jsx)(s.p,{children:"To register multiple services, repeat the request with different URLs."}),"\n",(0,t.jsxs)(s.blockquote,{children:["\n",(0,t.jsxs)(s.p,{children:["For other types of models, please check the ",(0,t.jsx)(s.a,{href:"/docs/llama-nexus/register",children:"Register"})," guide"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"call-the-service",children:"Call the service"}),"\n",(0,t.jsx)(s.p,{children:"Since Llama-Nexus is OpenAI-compatible, you can use any OpenAI-compatible client or the API spec to call your services:"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'curl -X POST http://localhost:3389/v1/chat/completions \\\n  -H \'accept: application/json\' \\\n  -H \'Content-Type: application/json\' \\\n  -d \'{"messages":[{"role":"system", "content": "You are a helpful assistant."},{"role":"user", "content": "What is the weather in Singapore?"}], "model": "your_model_name"}\'\n'})})]})}function h(e={}){const{wrapper:s}={...(0,n.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(u,{...e})}):u(e)}},8453:(e,s,a)=>{a.d(s,{R:()=>r,x:()=>i});var t=a(6540);const n={},l=t.createContext(n);function r(e){const s=t.useContext(l);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function i(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),t.createElement(l.Provider,{value:s},e.children)}}}]);